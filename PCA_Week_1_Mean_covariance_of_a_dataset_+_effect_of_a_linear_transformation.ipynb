{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA Week 1 : Mean/covariance of a dataset + effect of a linear transformation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PNzRpVmzH21"
      },
      "source": [
        "# **Week 1: Mean/Covariance of a data set and effect of a linear transformation**\n",
        "\n",
        "In this week, we are going to investigate how the mean and (co)variance of a dataset changes when we apply affine transformation to the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEX08hcmzjXM"
      },
      "source": [
        "# **Learning objectives**\n",
        "\n",
        "1.   Get Farmiliar with basic programming using Python and Numpy/Scipy.\n",
        "2.   Learn to appreciate implementing functions to compute statistics of dataset in vectorized way.\n",
        "1.   Understand the effects of affine transformations on a dataset.\n",
        "2.   Understand the importance of testing in programming for machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g00YbJf_0K70"
      },
      "source": [
        "First, let's import the packages that we will use for the week"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZvyo83q0M-Y"
      },
      "source": [
        "# PACKAGE: DO NOT EDIT\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('fivethirtyeight')\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "import time\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDSs1fjp0Rqp"
      },
      "source": [
        "%matplotlib inline\n",
        "from ipywidgets import interact"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7MFM1LB0U7v"
      },
      "source": [
        "Next, we are going to retrieve Olivetti faces dataset.\n",
        "\n",
        "When working with some datasets, before digging into further analysis, it is almost always useful to do a few things to understand your dataset. First of all, answer the following set of questions:\n",
        "\n",
        "1.   What is the size of your dataset?\n",
        "2.   What is the dimensionality of your data?\n",
        "\n",
        "The dataset we have are usually stored as 2D matrices, then it would be really important to know which dimension represents the dimension of the dataset, and which represents the data points in the dataset.\n",
        "\n",
        "**When you implement the functions for your assignment, make sure you read the docstring for what each dimension of your inputs represents the data points, and which represents the dimensions of the dataset!**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lahn7iQY00D6"
      },
      "source": [
        "image_shape = (64, 64)\n",
        "# Load faces data\n",
        "dataset = fetch_olivetti_faces(data_home='./')\n",
        "faces = dataset.data\n",
        "\n",
        "print('Shape of the faces dataset: {}'.format(faces.shape))\n",
        "print('{} data points'.format(faces.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWIS2Yas01TJ"
      },
      "source": [
        "When your dataset are images, it's a really good idea to see what they look like.\n",
        "\n",
        "One very convenient tool in Jupyter is the interact widget, which we use to visualize the images (faces). For more information on how to use interact, have a look at the documentation [here](http://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zadQGBKn1DUS"
      },
      "source": [
        "def show_face(face):\n",
        "    plt.figure()\n",
        "    plt.imshow(face.reshape((64, 64)), cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir8YCMjd1GWD"
      },
      "source": [
        "@interact(n=(0, len(faces)-1))\n",
        "def display_faces(n=0):\n",
        "    plt.figure()\n",
        "    plt.imshow(faces[n].reshape((64, 64)), cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XteB1D9G1Kl5"
      },
      "source": [
        "# **1. Mean and Covariance of a Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inWNxTQ-1Wh7"
      },
      "source": [
        "def mean_naive(X):\n",
        "    \"\"\"Compute the mean for a dataset by iterating over the dataset\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    X: (N, D) ndarray representing the dataset.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    mean: (D, ) ndarray which is the mean of the dataset.\n",
        "    \"\"\"\n",
        "    N, D = X.shape\n",
        "    \n",
        "    mean = np.zeros(D)\n",
        "    for n in range(N):\n",
        "        for i in range(D):\n",
        "            mean[i] = mean[i] + X[n, i]\n",
        "    \n",
        "    mean = mean/N\n",
        "        \n",
        "    return mean\n",
        "\n",
        "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
        "def cov_naive(X):\n",
        "    \"\"\"Compute the covariance for a dataset\n",
        "    Arguments\n",
        "    ---------\n",
        "    X: (N, D) ndarray representing the dataset.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    covariance: (D, D) ndarray which is the covariance matrix of the dataset.\n",
        "    \n",
        "    \"\"\"\n",
        "    N, D = X.shape\n",
        "    covariance = np.zeros((D, D))\n",
        "    mat = np.zeros((N, D))\n",
        "    mean = mean_naive(X)\n",
        "    for i in range(N):\n",
        "        mat[i] = X[i,:] - mean\n",
        "    for i in range(D):\n",
        "        for j in range(D):\n",
        "            covariance[i, j] = covariance[i, j] + mat[:,i]@mat[:,j]\n",
        "    return covariance/N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coSWxcDt1bMD"
      },
      "source": [
        "mean_naive(faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFuvjaCG1d6u"
      },
      "source": [
        "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
        "\n",
        "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
        "def mean(X):\n",
        "    \"\"\"Compute the mean for a dataset\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    X: (N, D) ndarray representing the dataset.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    mean: (D, ) ndarray which is the mean of the dataset.\n",
        "    \"\"\"\n",
        "    mean = np.mean(X, axis = 0) # EDIT THIS\n",
        "    return mean\n",
        " \n",
        "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
        "def cov(X):\n",
        "    \"\"\"Compute the covariance for a dataset\n",
        "    Arguments\n",
        "    ---------\n",
        "    X: (N, D) ndarray representing the dataset.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    covariance_matrix: (D, D) ndarray which is the covariance matrix of the dataset.\n",
        "    \n",
        "    \"\"\"\n",
        "    # It is possible to vectorize our code for computing the covariance, i.e. we do not need to explicitly\n",
        "    # iterate over the entire dataset as looping in Python tends to be slow\n",
        "    N, D = X.shape\n",
        "    covariance_matrix = np.cov(X, rowvar=False, bias=True) # EDIT THIS\n",
        "    return covariance_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGu6PWbp1haA"
      },
      "source": [
        "mean(faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMagaiTG1kVE"
      },
      "source": [
        "cov(faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "155dJal81nVR"
      },
      "source": [
        "X = np.random.randn(100, 5)\n",
        "cov(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwD9G-vA1sL0"
      },
      "source": [
        "cov_naive(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICRdxsvc1uDV"
      },
      "source": [
        "With the mean function implemented, let's take a look at the mean face of our dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvSggDB01xXP"
      },
      "source": [
        "def mean_face(faces):\n",
        "    \"\"\"Compute the mean of the `faces`\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    faces: (N, 64 * 64) ndarray representing the faces dataset.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    mean_face: (64, 64) ndarray which is the mean of the faces.\n",
        "    \"\"\"\n",
        "    mean_face = mean(faces)\n",
        "    return mean_face\n",
        "\n",
        "plt.imshow(mean_face(faces).reshape((64, 64)), cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaYXcfUj12rS"
      },
      "source": [
        "One of the advantage of writing vectorized code is speedup gained when working on larger dataset. Loops in Python are slow, and most of the time you want to utilise the fast native code provided by Numpy without explicitly using for loops. To put things into perspective, we can benchmark the two different implementation with the %time function in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT3qy_we15S2"
      },
      "source": [
        "# We have some huge data matrix, and we want to compute its mean\n",
        "X = np.random.randn(100000, 20)\n",
        "# Benchmarking time for computing mean\n",
        "%time mean_naive(X)\n",
        "%time mean(X)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj0ieLLp18KT"
      },
      "source": [
        "# Benchmarking time for computing covariance\n",
        "%time cov_naive(X)\n",
        "%time cov(X)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eOtK8ND1_9o"
      },
      "source": [
        "Alternatively, we can also see how running time increases as we increase the size of our dataset. In the following cell, we run mean, mean_naive and cov, cov_naive for many times on different sizes of the dataset and collect their running time. If you are less familiar with Python, you may want to spend some time understanding what the code does. Understanding how your code scales with the size of your dataset (or dimensionality of the dataset) is crucial when you want to apply your algorithm to larger dataset. This is really important when we propose alternative methods a more efficient algorithms to solve the same problem. We will use these techniques again later in this course to analyze the running time of our code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-X3gh9n2C3P"
      },
      "source": [
        "def time(f, repeat=100):\n",
        "    \"\"\"A helper function to time the execution of a function.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    f: a function which we want to time it.\n",
        "    repeat: the number of times we want to execute `f`\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    the mean and standard deviation of the execution.\n",
        "    \"\"\"\n",
        "    times = []\n",
        "    for _ in range(repeat):\n",
        "        start = timeit.default_timer()\n",
        "        f()\n",
        "        stop = timeit.default_timer()\n",
        "        times.append(stop-start)\n",
        "    return np.mean(times), np.std(times)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aaNe4pn2Gvz"
      },
      "source": [
        "fast_time = []\n",
        "slow_time = []\n",
        "\n",
        "for size in np.arange(100, 5000, step=100):\n",
        "    X = np.random.randn(size, 20)\n",
        "    f = lambda : mean(X)\n",
        "    mu, sigma = time(f)\n",
        "    fast_time.append((size, mu, sigma))\n",
        "    \n",
        "    f = lambda : mean_naive(X)\n",
        "    mu, sigma = time(f)\n",
        "    slow_time.append((size, mu, sigma))\n",
        "\n",
        "fast_time = np.array(fast_time)\n",
        "slow_time = np.array(slow_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9s9Mqjl2J5J"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.errorbar(fast_time[:,0], fast_time[:,1], fast_time[:,2], label='fast mean', linewidth=2)\n",
        "ax.errorbar(slow_time[:,0], slow_time[:,1], slow_time[:,2], label='naive mean', linewidth=2)\n",
        "ax.set_xlabel('size of dataset')\n",
        "ax.set_ylabel('running time')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWumnMav2Mbj"
      },
      "source": [
        "## === FILL IN THIS, follow the approach we have above ===\n",
        "fast_time_cov = []\n",
        "slow_time_cov = []\n",
        "for size in np.arange(100, 5000, step=100):\n",
        "    X = np.random.randn(size, 20)\n",
        "    f = lambda : cov(X)               # EDIT THIS\n",
        "    mu, sigma = time(f) # EDIT THIS\n",
        "    fast_time_cov.append((size, mu, sigma))\n",
        "    \n",
        "    f = lambda :cov_naive(X)        # EDIT THIS\n",
        "    mu, sigma = time(f) # EDIT THIS\n",
        "    slow_time_cov.append((size, mu, sigma))\n",
        "\n",
        "fast_time_cov = np.array(fast_time_cov)\n",
        "slow_time_cov = np.array(slow_time_cov)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VibAAHbz2PLI"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.errorbar(fast_time_cov[:,0], fast_time_cov[:,1], fast_time_cov[:,2], label='fast covariance', linewidth=2)\n",
        "ax.errorbar(slow_time_cov[:,0], slow_time_cov[:,1], slow_time_cov[:,2], label='naive covariance', linewidth=2)\n",
        "ax.set_xlabel('size of dataset')\n",
        "ax.set_ylabel('running time')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbeYv9Fh2Tzr"
      },
      "source": [
        "# **2. Affine Transformation of Dataset**\n",
        "In this week we are also going to verify a few properties about the mean and covariance of affine transformation of random variables.\n",
        "\n",
        "Consider a data matrix  ùëã  of size (N, D). We would like to know what is the covariance when we apply affine transformation  ùê¥ùë•ùëñ+ùëè  for each datapoint  ùë•ùëñ  in  ùëã . i.e. we would like to know what happens to the mean and covariance for the new dataset if we apply affine transformation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1IaE4KC2cmP"
      },
      "source": [
        "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
        "\n",
        "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
        "def affine_mean(mean, A, b):\n",
        "    \"\"\"Compute the mean after affine transformation\n",
        "    Args:\n",
        "        mean: ndarray, the mean vector\n",
        "        A, b: affine transformation applied to x\n",
        "    Returns:\n",
        "        mean vector after affine transformation\n",
        "    \"\"\"\n",
        "    affine_m = np.zeros(mean.shape) # EDIT THIS\n",
        "    affine_m = A@mean + b\n",
        "    return affine_m\n",
        "\n",
        "# ===YOU SHOULD EDIT THIS FUNCTION===\n",
        "def affine_covariance(S, A, b):\n",
        "    \"\"\"Compute the covariance matrix after affine transformation\n",
        "    Args:\n",
        "        S: ndarray, the covariance matrix\n",
        "        A, b: affine transformation applied to each element in X        \n",
        "    Returns:\n",
        "        covariance matrix after the transformation\n",
        "    \"\"\"\n",
        "    affine_cov = np.zeros(S.shape) # EDIT THIS\n",
        "    affine_cov = A@S@A.T\n",
        "    return affine_cov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOid5NxK2fQv"
      },
      "source": [
        "Once the two functions above are implemented, we can verify the correctness our implementation. Assuming that we have some  ùê¥  and  ùëè "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsBl5JDJ2hsT"
      },
      "source": [
        "random = np.random.RandomState(42)\n",
        "A = random.randn(4,4)\n",
        "b = random.randn(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvFzu73r2krt"
      },
      "source": [
        "Next we can generate some random dataset  ùëã"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAA05Fzm2nXJ"
      },
      "source": [
        "X = random.randn(100, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4E437nR2q6d"
      },
      "source": [
        "Assuming that for some dataset  ùëã , the mean and covariance are  ùëö ,  ùëÜ , and for the new dataset after affine transformation  ùëã‚Ä≤ , the mean and covariance are  ùëö‚Ä≤  and  ùëÜ‚Ä≤ , then we would have the following identity:\n",
        "\n",
        "\n",
        "\n",
        "> ùëö‚Ä≤=affine_mean(ùëö,ùê¥,ùëè)\n",
        "\n",
        "\n",
        "> ùëÜ‚Ä≤=affine_covariance(ùëÜ,ùê¥,ùëè)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGxihYqI2zBp"
      },
      "source": [
        "X1 = ((A @ (X.T)).T + b)  # applying affine transformation once\n",
        "X2 = ((A @ (X1.T)).T + b) # and again"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SkUTCZL3O_H"
      },
      "source": [
        "np.testing.assert_almost_equal(mean(X1), affine_mean(mean(X), A, b))\n",
        "np.testing.assert_almost_equal(cov(X1),  affine_covariance(cov(X), A, b))\n",
        "print('correct')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLTCVbu93S49"
      },
      "source": [
        "np.testing.assert_almost_equal(mean(X2), affine_mean(mean(X1), A, b))\n",
        "np.testing.assert_almost_equal(cov(X2),  affine_covariance(cov(X1), A, b))\n",
        "print('correct')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "573ZTHXh3UWL"
      },
      "source": [
        "One very useful way to compare whether arrays are equal/similar is use the helper functions in numpy.testing.\n",
        "\n",
        "Check the Numpy [documentation](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.testing.html) for details.\n",
        "\n",
        "If you are interested in learning more about floating point arithmetic, here is a good [paper](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6768)."
      ]
    }
  ]
}